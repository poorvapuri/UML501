{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1s10yQ/UtbaAlpm48xJiC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poorvapuri/UML501/blob/main/Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1: K-Fold Cross Validation for Multiple Linear Regression (Least Square Error Fit)"
      ],
      "metadata": {
        "id": "h-iWEbmP3v0v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GauC_UkDuGgW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adbc31b1-2228-4b47-bb1e-994dd6aa0c96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: R2 Score = 0.9180\n",
            "Fold 2: R2 Score = 0.9146\n",
            "Fold 3: R2 Score = 0.9116\n",
            "Fold 4: R2 Score = 0.9193\n",
            "Fold 5: R2 Score = 0.9244\n",
            "\n",
            "Best Beta (from CV): [1.23161736e+06 2.30225051e+05 1.63956839e+05 1.21115120e+05\n",
            " 7.83467170e+02 1.50662447e+05]\n",
            "Best R2 Score: 0.9243869413350317\n",
            "\n",
            "Final Test R2 Score (with best beta): 0.9146818498916267\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "url = \"/content/USA_Housing.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# a) Separate features & target\n",
        "X = data.drop(\"Price\", axis=1).values\n",
        "y = data[\"Price\"].values\n",
        "\n",
        "# b) Scale input features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# c) 5-fold division\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "best_r2 = -np.inf\n",
        "best_beta = None\n",
        "\n",
        "# d) Perform 5-fold CV\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(X), 1):\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    # Least Square Solution (Normal Equation)\n",
        "    # Add a column of ones for the intercept term\n",
        "    X_train_intercept = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
        "    X_test_intercept = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
        "\n",
        "    beta = np.linalg.pinv(X_train_intercept.T @ X_train_intercept) @ (X_train_intercept.T @ y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = X_test_intercept @ beta\n",
        "\n",
        "    # R2 Score\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"Fold {fold}: R2 Score = {r2:.4f}\")\n",
        "\n",
        "    if r2 > best_r2:\n",
        "        best_r2 = r2\n",
        "        best_beta = beta\n",
        "\n",
        "print(\"\\nBest Beta (from CV):\", best_beta)\n",
        "print(\"Best R2 Score:\", best_r2)\n",
        "\n",
        "# e) Train with best beta on 70% data, test on 30%\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, random_state=42)\n",
        "\n",
        "# Add a column of ones for the intercept term\n",
        "X_train_intercept = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
        "X_test_intercept = np.hstack((np.ones((X_test.shape[0], 1)), X_test))\n",
        "\n",
        "\n",
        "# Compute beta again on 70% using Normal Equation\n",
        "beta_final = np.linalg.pinv(X_train_intercept.T @ X_train_intercept) @ (X_train_intercept.T @ y_train)\n",
        "\n",
        "y_pred_final = X_test_intercept @ beta_final\n",
        "final_r2 = r2_score(y_test, y_pred_final)\n",
        "\n",
        "print(\"\\nFinal Test R2 Score (with best beta):\", final_r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2) Concept of Validation set for Multiple Linear Regression (Gradient Descent\n",
        "Optimization)"
      ],
      "metadata": {
        "id": "rVYJuP1e39HA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Reuse dataset\n",
        "X = data.drop(\"Price\", axis=1).values\n",
        "y = data[\"Price\"].values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# Split into train (56%), val (14%), test (30%)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "X_train, X_val, y_temp_train, y_val = train_test_split(X_temp, y_temp, test_size=0.20, random_state=42)\n",
        "# (0.20 of 70% = 14%)\n",
        "\n",
        "# Add bias column\n",
        "X_train = np.c_[np.ones(X_train.shape[0]), X_train]\n",
        "X_val   = np.c_[np.ones(X_val.shape[0]), X_val]\n",
        "X_test  = np.c_[np.ones(X_test.shape[0]), X_test]\n",
        "\n",
        "# Gradient Descent Function\n",
        "def gradient_descent(X, y, lr, iterations):\n",
        "    m, n = X.shape\n",
        "    beta = np.zeros(n)\n",
        "    for _ in range(iterations):\n",
        "        gradient = -(2/m) * X.T @ (y - X @ beta)\n",
        "        beta -= lr * gradient\n",
        "    return beta\n",
        "\n",
        "learning_rates = [0.001, 0.01, 0.1, 1]\n",
        "best_r2 = -np.inf\n",
        "best_beta = None\n",
        "\n",
        "for lr in learning_rates:\n",
        "    beta = gradient_descent(X_train, y_temp_train, lr, 1000)\n",
        "\n",
        "    y_val_pred = X_val @ beta\n",
        "\n",
        "    # Check for inf or NaN in predictions before calculating R2\n",
        "    if np.any(np.isinf(y_val_pred)) or np.any(np.isnan(y_val_pred)):\n",
        "      r2_val = -np.inf\n",
        "    else:\n",
        "      r2_val = r2_score(y_val, y_val_pred)\n",
        "\n",
        "    print(f\"LR={lr} | Val R2={r2_val:.4f}\")\n",
        "\n",
        "    if r2_val > best_r2:\n",
        "        best_r2 = r2_val\n",
        "        best_beta = beta\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "y_test_pred = X_test @ best_beta\n",
        "final_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "\n",
        "print(\"\\nBest Beta (from validation):\", best_beta)\n",
        "print(\"Final Test R2 Score (with best beta):\", final_r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuRo3YwZ4COE",
        "outputId": "190615f9-45ea-4036-8146-ac5508ee66d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR=0.001 | Val R2=0.6820\n",
            "LR=0.01 | Val R2=0.9098\n",
            "LR=0.1 | Val R2=0.9098\n",
            "LR=1 | Val R2=-inf\n",
            "\n",
            "Best Beta (from validation): [1232618.31836202  230067.95333238  163710.26584918  121680.22876975\n",
            "    2833.37135223  150657.57448494]\n",
            "Final Test R2 Score (with best beta): 0.9147569598865972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_regression.py:1275: RuntimeWarning: overflow encountered in square\n",
            "  numerator = xp.sum(weight * (y_true - y_pred) ** 2, axis=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3) Pre-processing and Multiple Linear Regression"
      ],
      "metadata": {
        "id": "o_caJdCu4bgA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
        "cols = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\n",
        "        \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\", \"wheel_base\",\n",
        "        \"length\", \"width\", \"height\", \"curb_weight\", \"engine_type\", \"num_cylinders\",\n",
        "        \"engine_size\", \"fuel_system\", \"bore\", \"stroke\", \"compression_ratio\",\n",
        "        \"horsepower\", \"peak_rpm\", \"city_mpg\", \"highway_mpg\", \"price\"]\n",
        "\n",
        "df = pd.read_csv(url, names=cols)\n",
        "df.replace(\"?\", np.nan, inplace=True)\n",
        "\n",
        "# 2) Drop rows where price is NaN (assignment requirement)\n",
        "df = df.dropna(subset=[\"price\"]).copy()\n",
        "# ensure price numeric\n",
        "df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n",
        "\n",
        "# Helper to convert written numbers (like 'two') to numeric\n",
        "num_map = {\n",
        "    \"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5, \"six\": 6,\n",
        "    \"eight\": 8, \"twelve\": 12\n",
        "}\n",
        "def text_to_number(x):\n",
        "    if pd.isna(x):\n",
        "        return np.nan\n",
        "    s = str(x).strip().lower()\n",
        "    if s in num_map:\n",
        "        return num_map[s]\n",
        "    try:\n",
        "        return float(s)\n",
        "    except:\n",
        "        return np.nan\n",
        "\n",
        "# 3(i) Convert 'num_doors' and 'num_cylinders' words to numbers\n",
        "df[\"num_doors\"] = df[\"num_doors\"].apply(text_to_number)\n",
        "df[\"num_cylinders\"] = df[\"num_cylinders\"].apply(text_to_number)\n",
        "\n",
        "# Define which columns to treat as categorical for different encodings\n",
        "label_cols = [\"make\", \"fuel_type\", \"aspiration\", \"engine_location\"]\n",
        "dummy_cols = [\"body_style\", \"drive_wheels\"]\n",
        "special_cols = [\"fuel_system\", \"engine_type\"]\n",
        "\n",
        "# 2 continued: Numeric columns -> convert to numeric and impute median\n",
        "# (treat everything not in label/dummy/special/price as numeric)\n",
        "excluded = set(label_cols + dummy_cols + special_cols + [\"price\"])\n",
        "numeric_cols = [c for c in df.columns if c not in excluded]\n",
        "\n",
        "for c in numeric_cols:\n",
        "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "    # central tendency imputation (median for numeric)\n",
        "    med = df[c].median()\n",
        "    df[c].fillna(med, inplace=True)\n",
        "\n",
        "# For categorical label columns: fill NaN with mode then LabelEncode\n",
        "for c in label_cols:\n",
        "    if df[c].isna().any():\n",
        "        mode_val = df[c].mode(dropna=True)\n",
        "        if not mode_val.empty:\n",
        "            df[c].fillna(mode_val[0], inplace=True)\n",
        "        else:\n",
        "            df[c].fillna(\"missing\", inplace=True)\n",
        "    df[c] = LabelEncoder().fit_transform(df[c].astype(str))\n",
        "\n",
        "# 3(ii) Dummy encoding for body_style and drive_wheels - fill NaN first\n",
        "for c in dummy_cols:\n",
        "    if df[c].isna().any():\n",
        "        mode_val = df[c].mode(dropna=True)\n",
        "        if not mode_val.empty:\n",
        "            df[c].fillna(mode_val[0], inplace=True)\n",
        "        else:\n",
        "            df[c].fillna(\"missing\", inplace=True)\n",
        "df = pd.get_dummies(df, columns=dummy_cols, drop_first=True)\n",
        "\n",
        "# 3(iii) special rules:\n",
        "# (iv) fuel_system: contains 'pfi' -> 1 else 0\n",
        "df[\"fuel_system\"] = df[\"fuel_system\"].fillna(\"\").astype(str).str.lower().apply(lambda x: 1 if \"pfi\" in x else 0)\n",
        "# 3(v) engine_type: replace values containing string ohc to 1 else all values to 0.\n",
        "df[\"engine_type\"] = df[\"engine_type\"].fillna(\"\").astype(str).str.lower().apply(lambda x: 1 if \"ohc\" in x else 0)\n",
        "\n",
        "# 4. Divide the dataset into input features and output variable. Scale input features.\n",
        "X = df.drop(\"price\", axis=1)\n",
        "y = df[\"price\"]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 5. Train a linear regressor on 70% of data and test on 30%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "r2_before_pca = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"R2 score before PCA: {r2_before_pca:.4f}\")\n",
        "\n",
        "# 6. Reduce dimensionality using PCA and train again\n",
        "pca = PCA(n_components=0.95) # Retain 95% of variance\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
        "\n",
        "model_pca = LinearRegression()\n",
        "model_pca.fit(X_train_pca, y_train_pca)\n",
        "\n",
        "y_pred_pca = model_pca.predict(X_test_pca)\n",
        "r2_after_pca = r2_score(y_test_pca, y_pred_pca)\n",
        "\n",
        "print(f\"R2 score after PCA: {r2_after_pca:.4f}\")\n",
        "\n",
        "# Discuss performance improvement\n",
        "if r2_after_pca > r2_before_pca:\n",
        "    print(\"\\nPerformance improved after PCA.\")\n",
        "elif r2_after_pca < r2_before_pca:\n",
        "    print(\"\\nPerformance decreased after PCA.\")\n",
        "else:\n",
        "    print(\"\\nPerformance did not change significantly after PCA.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyvRsYwA4aee",
        "outputId": "6abc46cc-89c2-4208-c381-02ba911f726e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 score before PCA: 0.8734\n",
            "R2 score after PCA: 0.8617\n",
            "\n",
            "Performance decreased after PCA.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1460536589.py:59: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[c].fillna(med, inplace=True)\n"
          ]
        }
      ]
    }
  ]
}