{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1DhDuhvjVrkzHO3NpFu15",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poorvapuri/UML501/blob/main/Assignment4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6cNvSd26xo8",
        "outputId": "471b4b4a-6006-4f2b-ba2f-59b81d0bbe16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Scraping complete! Saved to books.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
        "books = []\n",
        "\n",
        "# Loop through all 50 pages\n",
        "for page in range(1, 51):\n",
        "    url = base_url.format(page)\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "    for book in soup.find_all(\"article\", class_=\"product_pod\"):\n",
        "        title = book.h3.a[\"title\"]\n",
        "        price = book.find(\"p\", class_=\"price_color\").text.strip()\n",
        "        availability = book.find(\"p\", class_=\"instock availability\").text.strip()\n",
        "        star_rating = book.p[\"class\"][1]  # class=\"star-rating Three\" → [\"star-rating\",\"Three\"]\n",
        "\n",
        "        books.append([title, price, availability, star_rating])\n",
        "\n",
        "# Store in DataFrame\n",
        "df_books = pd.DataFrame(books, columns=[\"Title\", \"Price\", \"Availability\", \"Star Rating\"])\n",
        "df_books.to_csv(\"books.csv\", index=False)\n",
        "print(\"✅ Scraping complete! Saved to books.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "url = \"https://www.imdb.com/chart/top/\"\n",
        "\n",
        "# Configure Chrome options for headless mode\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "driver.get(url)\n",
        "time.sleep(3)  # wait for page to load\n",
        "\n",
        "movies = []\n",
        "\n",
        "rows = driver.find_elements(By.CSS_SELECTOR, \".ipc-metadata-list-summary-item\")\n",
        "for rank, row in enumerate(rows, start=1):\n",
        "    title = row.find_element(By.CSS_SELECTOR, \"h3\").text\n",
        "    year = row.find_element(By.CSS_SELECTOR, \".cli-title-metadata-item\").text\n",
        "    rating = row.find_element(By.CSS_SELECTOR, \".ipc-rating-star\").text.split()[0]\n",
        "    movies.append([rank, title, year, rating])\n",
        "\n",
        "driver.quit()\n",
        "\n",
        "df_movies = pd.DataFrame(movies, columns=[\"Rank\", \"Movie Title\", \"Year\", \"IMDB Rating\"])\n",
        "df_movies.to_csv(\"imdb_top250.csv\", index=False)\n",
        "print(\"✅ IMDB Top 250 saved to imdb_top250.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVZH7_2a9WoP",
        "outputId": "4c11f136-0bf8-43c6-cca9-485dc6b3d43f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ IMDB Top 250 saved to imdb_top250.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57fa9f52",
        "outputId": "83130056-0f14-4f18-8fbc-d51f02e0aecb"
      },
      "source": [
        "%pip install selenium"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.12/dist-packages (4.35.0)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.8.3)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.14.1)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.12/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://www.timeanddate.com/weather/\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "cities = []\n",
        "for row in soup.select(\"table tbody tr\"):\n",
        "    try:\n",
        "        city = row.find(\"a\").text\n",
        "        temp = row.find(\"td\", class_=\"rbi\").text\n",
        "        condition = row.find_all(\"td\")[2].text\n",
        "        cities.append([city, temp, condition])\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "df_weather = pd.DataFrame(cities, columns=[\"City\", \"Temperature\", \"Condition\"])\n",
        "df_weather.to_csv(\"weather.csv\", index=False)\n",
        "print(\"✅ Weather data saved to weather.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tHh_Iop__Bc",
        "outputId": "da1b00f3-fe48-452a-a574-bdca35973ff6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Weather data saved to weather.csv\n"
          ]
        }
      ]
    }
  ]
}