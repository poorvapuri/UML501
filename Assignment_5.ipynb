{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONuxSt2mdpDaEAkPPHxTyc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poorvapuri/UML501/blob/main/Assignment_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1\n"
      ],
      "metadata": {
        "id": "n-lgq5UFUpAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# Generate highly correlated dataset\n",
        "X = np.random.rand(500,7)\n",
        "X[:,1:] = X[:,[0]] + np.random.rand(500,6)*0.01\n",
        "y = 5*X[:,0] + 3*X[:,1] + 2*X[:,2] + np.random.randn(500)\n",
        "\n",
        "# Add bias column\n",
        "X = np.c_[np.ones(X.shape[0]), X]\n",
        "\n",
        "def ridge_gradient_descent(X, y, lr, lmbda, epochs=3000):\n",
        "    m, n = X.shape\n",
        "    w = np.zeros(n)\n",
        "\n",
        "    for _ in range(epochs):\n",
        "        y_pred = X.dot(w)\n",
        "        grad = (1/m) * X.T.dot(y_pred - y) + (lmbda/m) * w\n",
        "        grad[0] -= (lmbda/m) * w[0]  # bias not regularized\n",
        "\n",
        "        w = w - lr * grad\n",
        "\n",
        "        # if divergence detected, stop & return None\n",
        "        if np.isnan(w).any() or np.isinf(w).any():\n",
        "            return None, None, None\n",
        "\n",
        "    cost = (1/(2*m))*np.sum((X.dot(w) - y)**2) + (lmbda/(2*m))*np.sum(w[1:]**2)\n",
        "    return w, cost, r2_score(y, X.dot(w))\n",
        "\n",
        "learning_rates = [0.0001, 0.001, 0.01, 0.1]\n",
        "lambdas = [1e-15, 1e-10, 1e-5, 1e-3, 0, 1, 10, 20]\n",
        "\n",
        "best = None\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for lmbda in lambdas:\n",
        "        w, c, r2 = ridge_gradient_descent(X, y, lr, lmbda)\n",
        "\n",
        "        if w is None:\n",
        "            continue\n",
        "\n",
        "        if (best is None) or (r2 > best[3]):\n",
        "            best = (lr, lmbda, c, r2)\n",
        "\n",
        "print(\" Best Learning Rate:\", best[0])\n",
        "print(\" Best Lambda:\", best[1])\n",
        "print(\" Minimum Cost:\", best[2])\n",
        "print(\" Maximum R2 Score:\", best[3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "140Eku7VUSq8",
        "outputId": "dcf86366-7e1b-4a98-c8c2-fa763d8c9974"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Best Learning Rate: 0.1\n",
            " Best Lambda: 1e-15\n",
            " Minimum Cost: 0.4780047531549035\n",
            " Maximum R2 Score: 0.897330003854884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2\n"
      ],
      "metadata": {
        "id": "aSzTVB6SUZoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression,Ridge,Lasso\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "df = pd.read_csv(\"/content/Hitters.csv\").dropna()\n",
        "\n",
        "X = df.drop(\"Salary\",axis=1)\n",
        "y = df[\"Salary\"]\n",
        "\n",
        "cat = X.select_dtypes(include=\"object\").columns\n",
        "ct = ColumnTransformer([(\"ohe\",OneHotEncoder(drop='first'),cat)],remainder=\"passthrough\")\n",
        "X = ct.fit_transform(X)\n",
        "\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
        "\n",
        "lr = LinearRegression().fit(X_train,y_train)\n",
        "ridge = Ridge(alpha=0.5748).fit(X_train,y_train)\n",
        "lasso = Lasso(alpha=0.5748).fit(X_train,y_train)\n",
        "\n",
        "models = {\"Linear\":lr,\"Ridge\":ridge,\"Lasso\":lasso}\n",
        "\n",
        "for name,m in models.items():\n",
        "    pred = m.predict(X_test)\n",
        "    print(name,\": R2 =\",r2_score(y_test,pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXl5l7tvRcc2",
        "outputId": "99c78202-5d53-4751-b588-690752af326b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear : R2 = 0.4166986480172832\n",
            "Ridge : R2 = 0.4437353233291301\n",
            "Lasso : R2 = 0.43172177389455013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3\n"
      ],
      "metadata": {
        "id": "PRN60uTVRZBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import RidgeCV, LassoCV\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "boston = fetch_openml(name='boston', version=1, as_frame=True)\n",
        "X,y = boston.data, boston.target\n",
        "\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
        "\n",
        "ridge = RidgeCV(alphas=[0.01,0.1,1,10,100]).fit(X_train,y_train)\n",
        "lasso = LassoCV(cv=5).fit(X_train,y_train)\n",
        "\n",
        "print(\"Ridge best alpha:\",ridge.alpha_,\"R2:\",r2_score(y_test,ridge.predict(X_test)))\n",
        "print(\"Lasso best alpha:\",lasso.alpha_,\"R2:\",r2_score(y_test,lasso.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB7Ui_LJRDmC",
        "outputId": "da712e77-025c-4fb3-e9b1-542ebc2d8255"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge best alpha: 1.0 R2: 0.7633890084067051\n",
            "Lasso best alpha: 0.025342972941781578 R2: 0.7623867996124895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4\n"
      ],
      "metadata": {
        "id": "MJkjUVV1Q5AI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.special import expit\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "X = np.c_[np.ones(X.shape[0]),X]\n",
        "\n",
        "def logistic_regression_ovr(X,y,lr=0.01,epochs=2000):\n",
        "    classes = np.unique(y)\n",
        "    m,n = X.shape\n",
        "    W = np.zeros((len(classes),n))\n",
        "    for idx,c in enumerate(classes):\n",
        "        yc = (y==c).astype(int)\n",
        "        w = np.zeros(n)\n",
        "        for _ in range(epochs):\n",
        "            pred = expit(X.dot(w))\n",
        "            grad = (1/m)*X.T.dot(pred-yc)\n",
        "            w -= lr*grad\n",
        "        W[idx] = w\n",
        "    return W\n",
        "\n",
        "def predict_ovr(W,X):\n",
        "    probs = expit(X.dot(W.T))\n",
        "    return np.argmax(probs,axis=1)\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
        "W = logistic_regression_ovr(X_train,y_train)\n",
        "pred = predict_ovr(W,X_test)\n",
        "print(\"Accuracy:\",accuracy_score(y_test,pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzN4ad3OQ4pJ",
        "outputId": "40fbf073-7c1c-4d9c-e244-b5a90b38be1a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7666666666666667\n"
          ]
        }
      ]
    }
  ]
}